{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OscarRojasG/CLP-Framework/blob/main/CLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8ZDRgA3ic8m"
      },
      "source": [
        "# Generador de instancias\n",
        "\n",
        "Cada instancia se representa con el siguiente formato:\n",
        "\n",
        "```\n",
        "1                   # ID de la instancia\n",
        "587 233 220         # Dimensiones del contenedor (L W H)\n",
        "10                  # Número de tipos de cajas\n",
        "1 108 0 76 0 30 1 20\n",
        "2 110 0 43 1 25 1 11\n",
        "3 92 1 81 1 55 1 9\n",
        "4 81 0 33 1 28 1 9\n",
        "5 120 1 99 1 73 1 9\n",
        "6 111 0 70 1 48 1 13\n",
        "7 98 0 72 1 46 1 4\n",
        "8 95 0 66 0 31 1 12\n",
        "9 85 0 84 0 30 1 9\n",
        "10 71 0 32 1 25 1 10\n",
        "```\n",
        "\n",
        "Cada tipo de caja se describe en una línea con el siguiente formato:\n",
        "\n",
        "```\n",
        "id_caja  L  rotX  W  rotY  H  rotZ  cantidad\n",
        "1 108 0 76 0 30 1 20\n",
        "```\n",
        "\n",
        "Donde:\n",
        "\n",
        "* $L, W, H$ son las dimensiones de la caja\n",
        "* $rotX, rotY, rotZ$ es la factibilidad de que cada caja pueda ser rotada sobre los ejes X, Y, Z."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl6rstS7eied"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import random\n",
        "\n",
        "class BoxType:\n",
        "    def __init__(self, box_id, dims, rots, qty):\n",
        "        self.id = box_id        # identificador de la caja\n",
        "        self.dims = dims        # (L, W, H)\n",
        "        self.rots = rots        # (rotX, rotY, rotZ)\n",
        "        self.qty = qty          # cantidad de cajas\n",
        "\n",
        "\n",
        "class CLPInstance:\n",
        "    def __init__(self, container, boxes : list[BoxType]):\n",
        "        self.container = container  # (L, W, H)\n",
        "        self.n_types = len(boxes)\n",
        "        self.boxes = boxes          # lista de BoxType\n",
        "\n",
        "\n",
        "def instance(n_types=10, seed=None):\n",
        "    \"\"\"\n",
        "    Genera una sola instancia del CLP como objeto CLPInstance.\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        random.seed(seed)\n",
        "\n",
        "    # Dimensiones del contenedor (fijas en este caso)\n",
        "    l, w, h = 587, 233, 220\n",
        "\n",
        "    # Límites de dimensiones de las cajas\n",
        "    alpha = [30, 25, 20]   # mínimo largo, ancho, alto\n",
        "    beta  = [120, 100, 80] # máximo largo, ancho, alto\n",
        "    L = 2  # constante de estabilidad\n",
        "\n",
        "    # Volumen del contenedor\n",
        "    tc = l * w * h\n",
        "\n",
        "    dimension_box = []\n",
        "    cantidad_box_type = []\n",
        "    volumen_box_type = []\n",
        "    orientacion_box = []\n",
        "\n",
        "    # Genera tipos de cajas\n",
        "    for i in range(n_types):\n",
        "        # Dimensiones aleatorias dentro de los rangos\n",
        "        r_j = [random.randint(alpha[j], beta[j]) for j in range(3)]\n",
        "        aux_dim = [alpha[j] + (r_j[j] % (beta[j] - alpha[j] + 1)) for j in range(3)]\n",
        "        dimension_box.append(aux_dim)\n",
        "\n",
        "        # Inicializa cantidad\n",
        "        cantidad_box_type.append(1)\n",
        "\n",
        "        # Volumen de la caja\n",
        "        volumen_box_type.append(aux_dim[0] * aux_dim[1] * aux_dim[2])\n",
        "\n",
        "        # Orientación factible según la constante L\n",
        "        min_dim = min(aux_dim)\n",
        "        aux_orient = [1 if aux_dim[j] / min_dim < L else 0 for j in range(3)]\n",
        "        orientacion_box.append(aux_orient)\n",
        "\n",
        "    # Rellena hasta que no quepa más\n",
        "    volumen_cargo = 0\n",
        "    while True:\n",
        "        volumen_cargo = sum(cantidad_box_type[i] * volumen_box_type[i] for i in range(n_types))\n",
        "        aux = random.randint(0, n_types - 1)\n",
        "        v_k = volumen_box_type[aux]\n",
        "        if tc > volumen_cargo + v_k:\n",
        "            cantidad_box_type[aux] += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # Construye lista de BoxType\n",
        "    boxes = [\n",
        "        BoxType(i + 1, dimension_box[i], orientacion_box[i], cantidad_box_type[i])\n",
        "        for i in range(n_types)\n",
        "    ]\n",
        "\n",
        "    return CLPInstance(container=(l, w, h), boxes=boxes)\n",
        "\n",
        "\n",
        "def gen_instances(filename, n_instances=100, n_types=10, seed=None):\n",
        "    \"\"\"\n",
        "    Genera un archivo con varias instancias CLP en el formato definido.\n",
        "    \"\"\"\n",
        "    with open(filename, \"w\") as f:\n",
        "        # número total de instancias\n",
        "        f.write(str(n_instances) + \"\\n\")\n",
        "\n",
        "        for inst_id in range(1, n_instances + 1):\n",
        "            inst = instance(n_types=n_types, seed=(seed + inst_id) if seed is not None else None)\n",
        "\n",
        "            # encabezado de la instancia\n",
        "            f.write(f\"{inst_id}\\n\")\n",
        "            l, w, h = inst.container\n",
        "            f.write(f\"{l} {w} {h}\\n\")\n",
        "            f.write(f\"{inst.n_types}\\n\")\n",
        "\n",
        "            # tipos de cajas\n",
        "            for i, box in enumerate(inst.boxes):\n",
        "                Lc, Wc, Hc = box.dims\n",
        "                rotX, rotY, rotZ = box.rots\n",
        "                qty = box.qty\n",
        "\n",
        "                if inst_id == n_instances and i == len(inst.boxes) - 1:\n",
        "                    f.write(f\"{box.id} {Lc} {rotX} {Wc} {rotY} {Hc} {rotZ} {qty}\")\n",
        "                else:\n",
        "                    f.write(f\"{box.id} {Lc} {rotX} {Wc} {rotY} {Hc} {rotZ} {qty}\\n\")\n",
        "\n",
        "def read_instances(filename) -> list[CLPInstance]:\n",
        "    \"\"\"\n",
        "    Lee un archivo de instancias CLP y devuelve una lista de objetos CLPInstance.\n",
        "    \"\"\"\n",
        "    instances = []\n",
        "    with open(filename, \"r\") as f:\n",
        "        # número total de instancias\n",
        "        n_instances = int(f.readline().strip())\n",
        "\n",
        "        for _ in range(n_instances):\n",
        "            inst_id = int(f.readline().split()[0])  # id de la instancia\n",
        "\n",
        "            # dimensiones del contenedor\n",
        "            l, w, h = map(int, f.readline().split())\n",
        "\n",
        "            # número de tipos de cajas\n",
        "            n_types = int(f.readline().strip())\n",
        "\n",
        "            boxes = []\n",
        "            for _ in range(n_types):\n",
        "                parts = f.readline().split()\n",
        "                box_id = int(parts[0])\n",
        "                Lc = int(parts[1])\n",
        "                rotX = int(parts[2])\n",
        "                Wc = int(parts[3])\n",
        "                rotY = int(parts[4])\n",
        "                Hc = int(parts[5])\n",
        "                rotZ = int(parts[6])\n",
        "                qty = int(parts[7])\n",
        "\n",
        "                boxes.append(BoxType(box_id, (Lc, Wc, Hc), (rotX, rotY, rotZ), qty))\n",
        "\n",
        "            instances.append(CLPInstance(container=(l, w, h), boxes=boxes))\n",
        "\n",
        "    return instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcky6zU6n6Rc",
        "outputId": "64218247-c127-4541-e64c-a7a38d36dbb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<__main__.CLPInstance at 0x7bef15643800>,\n",
              " <__main__.CLPInstance at 0x7bef156722d0>,\n",
              " <__main__.CLPInstance at 0x7bef156723c0>,\n",
              " <__main__.CLPInstance at 0x7bef15672a50>,\n",
              " <__main__.CLPInstance at 0x7bef156730b0>]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gen_instances(\"prueba.txt\", n_instances=5, n_types=10, seed=1)\n",
        "read_instances(\"prueba.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHQY-PhzGt0i"
      },
      "source": [
        "# BSG-VCS\n",
        "\n",
        "Al ejecutar\n",
        "\n",
        "```\n",
        "./BSG_CLP prueba.txt -i 1 -t 10 --verbose2=5 > output.txt\n",
        "```\n",
        "\n",
        "se guardarán los bloques seleccionados por BSG para construir la solución, en conjunto con los $m=5$ bloques más prometedores para cada estado:\n",
        "\n",
        "```\n",
        "selected block:686 space:(362,0,103)\n",
        "  action block:686 eval: 752760 0.024314749 0.85935438 0.16666667 279914.38\n",
        "  action block:600 eval: 752760 0.1954876 0.76418638 0.16666667 144329.86\n",
        "  action block:147 eval: 376380 0.024314749 0.79643276 0.33333333 118606.5\n",
        "  action block:149 eval: 501840 0.024314749 0.73896542 0.25 110652.05\n",
        "  action block:123 eval: 501840 0.11661384 0.74613438 0.25 104129.09\n",
        "```\n",
        "\n",
        "Los valores a continuación de `eval` indican las métricas:\n",
        "\n",
        "```\n",
        "eval: V Loss CS 1/n VCS\n",
        "```\n",
        "\n",
        "Nótese que en algunos casos, el bloque elegido por BSG no está dentro de los $m$ más prometedores. Estos casos son de particular relevancia ya que la heurística \"falla\" en su evaluación. En estos casos se imprime un sexto bloque:\n",
        "\n",
        "```\n",
        "selected block:141 space:(282,169,113)\n",
        "  action block:2318 eval: 825600 0.068243858 0.68818263 0.2 125052.61\n",
        "  action block:550 eval: 495360 0.041233657 0.66613802 0.33333333 75069.99\n",
        "  action block:553 eval: 660480 0.055983909 0.60071472 0.25 61531.879\n",
        "  action block:568 eval: 660480 0.26440305 0.61178143 0.25 51578.982\n",
        "  action block:17 eval: 194532 0.007518797 0.70680679 1 48185.48\n",
        "  action block:141 eval: 330240 0.01910828 0.62544895 0.5 43153.121\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzl2DNQRUEh4",
        "outputId": "cd5ab6f4-26d2-4cc4-cd4a-b5ba6d89ae5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Flag could not be matched: 't'\n",
            "  ./BSG_CLP {OPTIONS} [instance-set]\n",
            "\n",
            "    ********* BSG-CLP *********.\n",
            "\n",
            "  OPTIONS:\n",
            "\n",
            "      -h, --help                        Display this help menu\n",
            "      -i[int]                           Instance\n",
            "      -f[string]                        Format: (BR, BRw, 1C)\n",
            "      --min_fr=[double]                 Minimum volume occupied by a block\n",
            "                                        (proportion)\n",
            "      -w[int]                           Beam width (nodes per level)\n",
            "      --seed=[int]                      Random seed\n",
            "      --alpha=[double]                  Alpha parameter\n",
            "      --beta=[double]                   Beta parameter\n",
            "      --gamma=[double]                  Gamma parameter\n",
            "      --delta=[double]                  Delta parameter\n",
            "      -p[double]                        p parameter\n",
            "      --json                            json output tuple\n",
            "      --verbose                         Show the actions to reach the solution\n",
            "      --verbose2=[layout]               Verbose v2\n",
            "      --plot                            plot tree\n",
            "      --fsb                             full-support blocks\n",
            "      --trace                           Trace\n",
            "      instance-set                      The name of the instance set\n",
            "      \"--\" can be used to terminate flag options and force all following\n",
            "      arguments to be treated as positional options\n",
            "\n",
            "    BSG Solver for CLP.\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!chmod +x BSG_CLP\n",
        "!./BSG_CLP prueba.txt -i 1 -t 10 --verbose2=500 > output.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OHtNanXVuQxh"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def parse_file(file_path):\n",
        "    results = []\n",
        "    current_block = None\n",
        "\n",
        "    re_selected = re.compile(r\"selected block:(\\d+)\\s+space:\\((\\d+),(\\d+),(\\d+)\\)\")\n",
        "    re_action = re.compile(r\"action block:(\\d+)\\s+eval:\\s+([0-9eE+.\\s\\-infINF]+)\")\n",
        "\n",
        "    # Abrimos el archivo y leemos su contenido\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # selected block\n",
        "            m_sel = re_selected.match(line)\n",
        "            if m_sel:\n",
        "                if current_block:\n",
        "                    results.append(current_block)\n",
        "                block_id = int(m_sel.group(1))\n",
        "                coords = tuple(map(int, m_sel.groups()[1:]))\n",
        "                current_block = (block_id, coords, [])\n",
        "                continue\n",
        "\n",
        "            # action block\n",
        "            m_act = re_action.match(line)\n",
        "            if m_act and current_block:\n",
        "                act_id = int(m_act.group(1))\n",
        "                tokens = m_act.group(2).split()\n",
        "                nums = []\n",
        "                for tok in tokens:\n",
        "                    try:\n",
        "                        nums.append(float(tok))\n",
        "                    except ValueError:\n",
        "                        # fallback por si aparece algo inesperado\n",
        "                        nums.append(float(\"nan\"))\n",
        "                current_block[2].append((act_id, nums))\n",
        "\n",
        "    if current_block:\n",
        "        results.append(current_block)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def selected_block_positions(data):\n",
        "    positions = []\n",
        "\n",
        "    for sel_id, coords, actions in data:\n",
        "        for idx, (act_id, _) in enumerate(actions, start=1):  # índice 1-based\n",
        "            if act_id == sel_id:\n",
        "                positions.append(idx)\n",
        "                break  # solo interesa la primera coincidencia\n",
        "\n",
        "    # contamos frecuencia de cada posición\n",
        "    freq = Counter(positions)\n",
        "\n",
        "    # rango completo de 1 .. max\n",
        "    max_pos = max(freq) if freq else 0\n",
        "    result = [(i, freq.get(i, 0)) for i in range(1, max_pos + 1)]\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "def expand_to_x(arr, x):\n",
        "    # Usamos un diccionario para mapear ids a sus frecuencias\n",
        "    expanded_dict = dict(arr)\n",
        "\n",
        "    # Asegurarse de que todos los ids hasta x estén presentes\n",
        "    for i in range(1, x + 1):\n",
        "        if i not in expanded_dict:\n",
        "            expanded_dict[i] = 0\n",
        "\n",
        "    # Convertimos el diccionario de nuevo a una lista de tuplas y la ordenamos\n",
        "    expanded_arr = sorted(expanded_dict.items())\n",
        "\n",
        "    return expanded_arr\n",
        "\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "def run_instance(exe_path, file_path, i, w, output_path=None):\n",
        "    \"\"\"Ejecuta BSG_CLP para una instancia y guarda la salida en un archivo .out dentro de una carpeta específica o en la misma ruta que file_path\"\"\"\n",
        "\n",
        "    # Si output_path es None, usar la misma carpeta que file_path\n",
        "    if output_path is None:\n",
        "        output_path = os.path.dirname(file_path)\n",
        "\n",
        "    # Obtener el nombre base de file_path sin la extensión\n",
        "    base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "    # Generar el nombre del archivo de salida con 'i' y extensión .out\n",
        "    output_file_path = os.path.join(output_path, f\"{base_filename}-{i}.out\")\n",
        "\n",
        "    # Ejecutar el proceso y capturar la salida\n",
        "    proc = subprocess.run(\n",
        "        [exe_path, file_path, \"-i\", str(i), \"-w\", str(w), f\"--verbose2={str(w*w)}\"],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.DEVNULL,\n",
        "        check=True,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    # Guardar la salida en el archivo de salida\n",
        "    with open(output_file_path, 'w') as f:\n",
        "        f.write(proc.stdout)\n",
        "\n",
        "\n",
        "\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "def run_file_instances_parallel(file_path, exe_path=\"./BSG_CLP\", w=8, max_workers=None):\n",
        "    # Leer número de instancias\n",
        "    with open(file_path, \"r\") as f:\n",
        "        num_instances = int(f.readline().strip())\n",
        "\n",
        "    # Crear la carpeta de salida con el nombre del archivo (sin la extensión) y añadir \".out\" al final\n",
        "    output_folder = os.path.splitext(os.path.basename(file_path))[0] + \".out\"  # Usamos el nombre del archivo sin la extensión y añadimos \".out\"\n",
        "    os.makedirs(output_folder, exist_ok=True)  # Crear la carpeta si no existe\n",
        "\n",
        "    # Ejecutar las instancias en paralelo\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
        "        for i in range(num_instances):\n",
        "            executor.submit(run_instance, exe_path, file_path, i, w, output_folder)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_cumulative_percentage(result):\n",
        "    # Convertir a arrays\n",
        "    positions = np.array([pos for pos, _ in result])\n",
        "    freqs = np.array([freq for _, freq in result])\n",
        "\n",
        "    # Frecuencia acumulada porcentual\n",
        "    cum_freq = np.cumsum(freqs)\n",
        "    cum_percent = cum_freq / cum_freq[-1] * 100\n",
        "\n",
        "    # Graficar\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(positions, cum_percent)\n",
        "    plt.xticks(range(0, positions.max() + 10, 10))\n",
        "    plt.xlabel(\"Posición\")\n",
        "    plt.ylabel(\"Frecuencia acumulada (%)\")\n",
        "    plt.title(\"Frecuencia acumulada porcentual por posición\")\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from math import log, inf\n",
        "\n",
        "def accumulate_results_from_folder(folder_path):\n",
        "    # Usamos un defaultdict para acumular los contadores\n",
        "    total_counts = defaultdict(int)\n",
        "\n",
        "    # Iterar sobre todos los archivos en la carpeta\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Verificar si es un archivo y si termina en \".out\" (puedes ajustarlo si es necesario)\n",
        "        if os.path.isfile(file_path) and file_path.endswith(\".out\"):\n",
        "            # Parsear el archivo y obtener el resultado\n",
        "            data = parse_file(file_path)\n",
        "            result = selected_block_positions(data)\n",
        "\n",
        "            # Acumular los resultados\n",
        "            for block_id, count in result:\n",
        "                total_counts[block_id] += count\n",
        "\n",
        "    # Convertir el defaultdict en una lista de tuplas ordenada por 'id'\n",
        "    accumulated_result = sorted(total_counts.items())\n",
        "\n",
        "    return accumulated_result\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from math import log\n",
        "\n",
        "def generate_train_data(data, pad=64):\n",
        "    X = []  # Para los datos de entrenamiento\n",
        "    Y = []  # Para las predicciones (vectores one-hot)\n",
        "    block_ids = []  # Para las ids de los bloques\n",
        "\n",
        "    # Recorremos cada bloque\n",
        "    for block in data:\n",
        "        # Extraemos las características del bloque (el tercer elemento en cada bloque)\n",
        "        features = [entry[1][:4] for entry in block[2]]  # Obtiene las características de cada tupla en el bloque\n",
        "\n",
        "        # Rellenamos con ceros si el número de características es menor que pad\n",
        "        while len(features) < pad:\n",
        "            features.append([0.0] * len(features[0]))  # Añadir una lista de ceros de la misma longitud que las características\n",
        "\n",
        "        # Añadimos las características de este bloque a X\n",
        "        X.append(features[:pad])  # Aseguramos que no se sobrepasen los \"pad\" elementos\n",
        "\n",
        "        # Extraemos el id del bloque (primer valor de la tupla)\n",
        "        block_id = block[0]\n",
        "\n",
        "        # Crear el vector one-hot para Y\n",
        "        one_hot = [0] * pad  # Inicializa un vector con ceros\n",
        "\n",
        "        # Encontrar la posición de block_id en las tuplas de cada bloque\n",
        "        for i, entry in enumerate(block[2]):\n",
        "            if entry[0] == block_id:  # Compara el id de la tupla con el id del bloque\n",
        "                one_hot[i] = 1  # Marca la posición correspondiente en el vector one-hot\n",
        "                break\n",
        "\n",
        "        # Rellenamos con ceros si la longitud de one_hot es menor que pad\n",
        "        while len(one_hot) < pad:\n",
        "            one_hot.append(0)  # Añadir ceros al final si hace falta\n",
        "\n",
        "        # Añadir el vector one-hot a Y\n",
        "        Y.append(one_hot[:pad])  # Aseguramos que no se sobrepasen los \"pad\" elementos\n",
        "\n",
        "        # Añadir las ids del bloque a block_ids y rellenar con ceros si es necesario\n",
        "        ids = [entry[0] for entry in block[2]]  # Extrae solo el ID de cada tupla\n",
        "        while len(ids) < pad:\n",
        "            ids.append(0)  # Rellenar con ceros hasta alcanzar \"pad\"\n",
        "        block_ids.append(ids[:pad])  # Aseguramos que no se sobrepasen los \"pad\" elementos\n",
        "\n",
        "    return X, Y, block_ids\n",
        "\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "def generate_data_from_folder(folder_path, pad=64):\n",
        "    all_X = []  # Lista para almacenar todos los datos de entrenamiento\n",
        "    all_Y = []  # Lista para almacenar todos los vectores one-hot\n",
        "    all_block_ids = []  # Lista para almacenar todos los block_ids\n",
        "\n",
        "    # Iterar sobre todos los archivos en la carpeta\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        if os.path.isfile(file_path):  # Solo procesar archivos (no directorios)\n",
        "            # Parsear el archivo\n",
        "            data = parse_file(file_path)\n",
        "\n",
        "            # Generar los datos de entrenamiento\n",
        "            X, Y, block_ids = generate_train_data(data, pad=pad)\n",
        "\n",
        "            # Agregar los datos del archivo actual a las listas generales\n",
        "            all_X.extend(X)\n",
        "            all_Y.extend(Y)\n",
        "            all_block_ids.extend(block_ids)\n",
        "\n",
        "    # Definir el nombre del archivo de salida basado en el nombre de la carpeta\n",
        "    folder_name = os.path.basename(folder_path)  # Obtiene el nombre de la carpeta\n",
        "    output_filename = folder_name.split('.')[0] + \".data\"  # Eliminar la extensión .out si está presente y agregar .data\n",
        "    output_path = os.path.join(os.path.dirname(folder_path), output_filename)  # Guardar el archivo en el nivel superior\n",
        "\n",
        "    # Guardar los datos en el archivo (en este caso, usaremos pickle para guardar en formato binario)\n",
        "    with open(output_path, \"wb\") as f:\n",
        "        pickle.dump({\"X\": all_X, \"Y\": all_Y, \"block_ids\": all_block_ids}, f)\n",
        "\n",
        "    print(f\"Datos guardados en: {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def load_data_from_file(file_path):\n",
        "    # Abrir el archivo .data y cargar los datos\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    # Extraer X, Y y block_ids\n",
        "    X = data[\"X\"]\n",
        "    Y = data[\"Y\"]\n",
        "    block_ids = data[\"block_ids\"]\n",
        "\n",
        "    return X, Y, block_ids\n",
        "\n",
        "\n",
        "def split_and_save_datasets(file_path, cuts, output_path):\n",
        "    \"\"\"Separa los datos en varios datasets según los cortes y guarda en archivos .data\"\"\"\n",
        "\n",
        "    # Añadir un \"1\" al principio del arreglo cuts para asegurar que el primer dataset sea considerado\n",
        "    cuts = [1] + cuts\n",
        "\n",
        "    # Asegurarse de que la carpeta de salida exista\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "\n",
        "    # Cargar los datos desde el archivo .data\n",
        "    print(f\"Procesando archivo: {file_path}\")\n",
        "    X, Y, block_ids = load_data_from_file(file_path)\n",
        "\n",
        "    # Crear un diccionario para almacenar los datasets\n",
        "    datasets = {i: {\"X\": [], \"Y\": [], \"block_ids\": []} for i in range(1, len(cuts))}\n",
        "\n",
        "    # Separar los datos según los cortes\n",
        "    for i, y_vector in enumerate(Y):\n",
        "        pos = y_vector.index(1)  # Encontrar la posición del 1 en el vector one-hot\n",
        "\n",
        "        # Asignar el dato al dataset correspondiente según el corte\n",
        "        for j in range(len(cuts)-1):\n",
        "            if pos < cuts[j+1]:\n",
        "                datasets[j + 1][\"X\"].append(X[i])\n",
        "                datasets[j + 1][\"Y\"].append(Y[i])\n",
        "                datasets[j + 1][\"block_ids\"].append(block_ids[i])\n",
        "                break  # Una vez asignado, salir del loop de cortes\n",
        "\n",
        "    # Guardar cada dataset en un archivo\n",
        "    for i, dataset in datasets.items():\n",
        "        # Generar el nombre del archivo con base en el corte\n",
        "        start_cut = cuts[i-1] + 1 if i > 1 else 1\n",
        "        end_cut = cuts[i]  # Cortes entre `cuts[i-1]` y `cuts[i]`\n",
        "\n",
        "        output_filename = f\"{start_cut}-{end_cut}.data\"\n",
        "        output_file_path = os.path.join(output_path, output_filename)\n",
        "\n",
        "        # Guardar el dataset en el archivo\n",
        "        with open(output_file_path, \"wb\") as f:\n",
        "            pickle.dump({\"X\": dataset[\"X\"], \"Y\": dataset[\"Y\"], \"block_ids\": dataset[\"block_ids\"]}, f)\n",
        "\n",
        "        print(f\"Dataset guardado en: {output_file_path}\")\n",
        "\n",
        "\n",
        "def remove_elements_with_zero(X, Y, blocks_ids):\n",
        "    # Crear una lista de índices a eliminar\n",
        "    indices_to_remove = []\n",
        "\n",
        "    # Recorre blocks_ids y encuentra los índices que contienen al menos un 0\n",
        "    for idx, arr in enumerate(blocks_ids):\n",
        "        if 0 in arr:\n",
        "            indices_to_remove.append(idx)\n",
        "\n",
        "    # Eliminar los elementos en X, Y y blocks_ids correspondientes a los índices encontrados\n",
        "    X_filtered = [x for i, x in enumerate(X) if i not in indices_to_remove]\n",
        "    Y_filtered = [y for i, y in enumerate(Y) if i not in indices_to_remove]\n",
        "    blocks_ids_filtered = [block for i, block in enumerate(blocks_ids) if i not in indices_to_remove]\n",
        "\n",
        "    return X_filtered, Y_filtered, blocks_ids_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6zqCtXCKgm_",
        "outputId": "45963a56-97ec-44f6-d38c-e4a5ad2c778c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Metasolver'...\n",
            "remote: Enumerating objects: 60593, done.\u001b[K\n",
            "remote: Counting objects: 100% (230/230), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 60593 (delta 186), reused 161 (delta 160), pack-reused 60363 (from 3)\u001b[K\n",
            "Receiving objects: 100% (60593/60593), 573.42 MiB | 24.33 MiB/s, done.\n",
            "Resolving deltas: 100% (8796/8796), done.\n",
            "Updating files: 100% (7475/7475), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rilianx/Metasolver.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZboFUcX6e_Mo"
      },
      "outputs": [],
      "source": [
        "run_file_instances_parallel(\"Metasolver/problems/clp/benchs/BR/BR1.txt\", exe_path=\"./BSG_CLP\", w=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "lYsip8FvisQT",
        "outputId": "5fcebe56-23dd-4033-95b1-eb24018b1c2d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "acumr = accumulate_results_from_folder(\"BR1.out\")\n",
        "acumr = expand_to_x(acumr, 64)\n",
        "plot_cumulative_percentage(acumr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGofs35BfhRe"
      },
      "outputs": [],
      "source": [
        "data = parse_file(\"BR1.out/BR1-0.out\")\n",
        "generate_train_data(data, pad=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw-d4r8ffmtF"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de uso\n",
        "folder_path = \"BR1.out\"  # Carpeta que contiene los archivos\n",
        "generate_data_from_folder(folder_path, pad=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxX6XclUfpf1"
      },
      "outputs": [],
      "source": [
        "X, Y, blocks_ids = load_data_from_file(\"BR1.data\")\n",
        "print(len(X))\n",
        "print(len(Y))\n",
        "print(len(blocks_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FoLtbBLUrWz",
        "outputId": "83cafb07-1256-4da9-d7f4-44665a3c8ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando archivo: BR1.data\n",
            "Dataset guardado en: BR1-datasets/1-1.data\n",
            "Dataset guardado en: BR1-datasets/2-7.data\n",
            "Dataset guardado en: BR1-datasets/8-64.data\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo de uso\n",
        "file_path = \"BR1.data\"  # Archivo .data de entrada\n",
        "output_path = \"BR1-datasets\"  # Carpeta donde se guardarán los nuevos datasets\n",
        "cuts = [1, 7, 64]  # Los cortes\n",
        "\n",
        "split_and_save_datasets(file_path, cuts, output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWgXTxd_aM3Y",
        "outputId": "3faf1a82-d5be-494e-b9b1-487cb59cbd10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "414"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, Y, blocks_ids = load_data_from_file(\"BR1-datasets/1-1.data\")\n",
        "len(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SAFI5Cmb6rB"
      },
      "outputs": [],
      "source": [
        "gen_instances(\"E4.txt\", n_instances=1000, n_types=10, seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "MywrBZnNcNzZ",
        "outputId": "b0b76f5b-682c-4c96-83ef-fc353c0139cf"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4265358604.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_file_instances_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"E4.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexe_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./BSG_CLP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2860138112.py\u001b[0m in \u001b[0;36mrun_file_instances_parallel\u001b[0;34m(file_path, exe_path, w, max_workers)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# Ejecutar las instancias en paralelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexe_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/process.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor_manager_thread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor_manager_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0;31m# To reduce the risk of opening too many files, remove references to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;31m# objects that use file descriptors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "run_file_instances_parallel(\"E4.txt\", exe_path=\"./BSG_CLP\", w=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "L7BT8IXtyt6K",
        "outputId": "5e88b0f8-b524-46fc-bc89-8d5f827886b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datos guardados en: E4.data\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'E4.data'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_data_from_folder(\"E4.out\", pad=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3At4SS3f0JTu",
        "outputId": "5f518819-1212-4017-d09c-5ecc0fabd7a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando archivo: E4.data\n",
            "Dataset guardado en: E4-datasets/1-1.data\n",
            "Dataset guardado en: E4-datasets/2-7.data\n",
            "Dataset guardado en: E4-datasets/8-64.data\n"
          ]
        }
      ],
      "source": [
        "split_and_save_datasets(\"E4.data\", [1, 7, 64], \"E4-datasets\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vInM-a60dvs",
        "outputId": "133accfc-e902-41a5-9fb0-082284f52d4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11387"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, Y, blocks_ids = load_data_from_file(\"E4-datasets/1-1.data\")\n",
        "len(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rLUwpNZdRFk",
        "outputId": "b87cafe3-3b65-4813-c53c-087a5c87fa1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4593"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xf, Yf, bf = remove_elements_with_zero(X, Y, blocks_ids)\n",
        "len(Xf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi0skqZX1F6a",
        "outputId": "cc1218fc-d648-4cb7-fdb0-63eab2b8289f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: E4-datasets/ (stored 0%)\n",
            "  adding: E4-datasets/2-7.data (deflated 73%)\n",
            "  adding: E4-datasets/8-64.data (deflated 68%)\n",
            "  adding: E4-datasets/1-1.data (deflated 81%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r E4-datasets.zip E4-datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip E4-datasets.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn9qRiQdatk-",
        "outputId": "ed792816-01bc-46c2-b92c-fb42908c5174"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  E4-datasets.zip\n",
            "   creating: E4-datasets/\n",
            "  inflating: E4-datasets/2-7.data    \n",
            "  inflating: E4-datasets/8-64.data   \n",
            "  inflating: E4-datasets/1-1.data    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbNtZkPI8Ijs"
      },
      "source": [
        "# Modelo y entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2q5XO5H8J5c",
        "outputId": "28311040-a8d5-4a0d-ac3e-a0aa6c304de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLPModel(\n",
            "  (input_projection): Linear(in_features=5, out_features=128, bias=True)\n",
            "  (layers): ModuleList(\n",
            "    (0-5): 6 x ModuleDict(\n",
            "      (multihead_attention): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "      (dense_layer): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (1): ReLU()\n",
            "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "      )\n",
            "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (output_projection): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CLPModel(nn.Module):\n",
        "    def __init__(self, input_dim, num_heads, head_dim, num_layers=2, dropout_rate=0):\n",
        "        super(CLPModel, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = head_dim\n",
        "\n",
        "        # Proyección de entrada\n",
        "        self.input_projection = nn.Linear(input_dim, num_heads * head_dim)\n",
        "\n",
        "        # Crear múltiples capas de atención y densa\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.ModuleDict({\n",
        "                'multihead_attention': nn.MultiheadAttention(\n",
        "                    embed_dim=num_heads * head_dim,\n",
        "                    num_heads=num_heads,\n",
        "                    dropout=dropout_rate\n",
        "                ),\n",
        "                'dense_layer': nn.Sequential(\n",
        "                    nn.Linear(num_heads * head_dim, 512),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(512, num_heads * head_dim)\n",
        "                ),\n",
        "                'norm1': nn.LayerNorm(num_heads * head_dim),\n",
        "                'norm2': nn.LayerNorm(num_heads * head_dim)\n",
        "            }) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Proyección de salida final\n",
        "        self.output_projection = nn.Linear(num_heads * head_dim, 1)\n",
        "\n",
        "    def generate_attention_mask(self, x, num_heads, padding_value=0):\n",
        "        # Identificar posiciones de padding en x\n",
        "        mask = (x.sum(dim=-1) == padding_value)  # [batch_size, seq_length]\n",
        "        mask = mask.unsqueeze(1).expand(-1, x.size(1), -1)\n",
        "        mask = mask.unsqueeze(1).expand(-1, num_heads, -1, -1)\n",
        "        mask = mask.reshape(-1, x.size(1), x.size(1))\n",
        "        mask = mask.to(dtype=torch.bool)\n",
        "        return mask\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_length, input_dim]\n",
        "        x = x.float()\n",
        "\n",
        "        # Proyección de entrada\n",
        "        x_proj = self.input_projection(x)\n",
        "\n",
        "        # Generar máscara de atención\n",
        "        attn_mask = self.generate_attention_mask(x, self.num_heads)\n",
        "\n",
        "        # Aplicar cada capa de atención y densa\n",
        "        for layer in self.layers:\n",
        "            x_proj = x_proj.permute(1, 0, 2)\n",
        "            attn_output, _ = layer['multihead_attention'](\n",
        "                x_proj, x_proj, x_proj, attn_mask=attn_mask\n",
        "            )\n",
        "            attn_output = attn_output.permute(1, 0, 2)\n",
        "            x_proj = x_proj.permute(1, 0, 2)\n",
        "            attn_output = layer['norm1'](attn_output + x_proj)\n",
        "            dense_output = layer['dense_layer'](attn_output)\n",
        "            x_proj = layer['norm2'](dense_output + attn_output)\n",
        "\n",
        "        # Máscara para softmax\n",
        "        mask = torch.zeros_like(x, dtype=torch.bool)\n",
        "        mask = (x * ~mask).sum(dim=-1) == 0\n",
        "        mask = mask.to(dtype=torch.bool)\n",
        "\n",
        "        # Proyección de salida final (logits)\n",
        "        output = self.output_projection(x_proj)  # [batch_size, seq_length, num_classes]\n",
        "\n",
        "        # Flatten\n",
        "        flat_output = output.view(output.size(0), -1)  # [batch_size, seq_length]\n",
        "\n",
        "        # Enmascarar los logits antes de la pérdida: asignar un valor muy negativo a los logits en las posiciones no válidas\n",
        "        flat_output = flat_output.masked_fill(mask, -1e9)  # Asignar un valor muy negativo a las posiciones no válidas\n",
        "\n",
        "        return flat_output  # Retorna los logits (sin aplicar softmax)\n",
        "\n",
        "\n",
        "# Parámetros del modelo\n",
        "input_dim = 5  # Dimensión de la entrada\n",
        "num_heads = 8  # Número de cabezas en la atención multi-cabeza\n",
        "head_dim = 16  # Dimensión de cada cabeza\n",
        "num_layers = 6  # Número de capas\n",
        "\n",
        "# Crear el modelo\n",
        "model = CLPModel(input_dim=input_dim, num_heads=num_heads, head_dim=head_dim, num_layers=num_layers)\n",
        "\n",
        "# Información del modelo\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKzr7e6n3G_s",
        "outputId": "46a8728d-40ea-4a03-85cf-11103d8b2404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([500, 64, 4]) torch.Size([500, 64])\n"
          ]
        }
      ],
      "source": [
        "X, Y, blocks_ids = load_data_from_file(\"E4-datasets/1-1.data\")\n",
        "X, Y, _ = remove_elements_with_zero(X, Y, blocks_ids)\n",
        "X = torch.tensor(X[:500])\n",
        "Y = torch.tensor(Y[:500])\n",
        "\n",
        "print(X.shape, Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "-8VmYzU64CH5",
        "outputId": "fb9dd772-ca35-4dd7-acde-ad80abd4475b"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'size'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1162773199.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Dividir el dataset en entrenamiento y prueba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         assert all(\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         ), \"Size mismatch between tensors\"\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         assert all(\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         ), \"Size mismatch between tensors\"\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "dataset = TensorDataset(X, Y)\n",
        "\n",
        "# Dividir el dataset en entrenamiento y prueba\n",
        "train_size = int(0.5 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "fnvaKxlA4In4",
        "outputId": "b08528b3-acf3-4b62-d222-4af6c1ce22a4"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2532131147.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Definir el modelo, la función de pérdida y el optimizador\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Pérdida sin reducción\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Definir el modelo, la función de pérdida y el optimizador\n",
        "loss_function = torch.nn.CrossEntropyLoss()  # Pérdida sin reducción\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Ciclo de entrenamiento\n",
        "epochs = 1\n",
        "\n",
        "history = {split: {'loss': [], 'acc': []} for split in ['train', 'val']}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0; total = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()  # Limpia los gradientes\n",
        "        outputs = model(X_batch)  # Obtenemos logits\n",
        "\n",
        "        # Calcular la pérdida para cada elemento en el batch\n",
        "        loss = loss_function(outputs, y_batch.argmax(dim=-1))\n",
        "\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Actualizar parámetros\n",
        "\n",
        "        train_loss += loss.item() * X_batch.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += y_batch.size(0)\n",
        "        correct += (predicted == y_batch.argmax(dim=1)).sum().item()\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_accuracy = 100 * correct / total\n",
        "    history['train']['loss'].append(train_loss)\n",
        "    history['train']['acc'].append(train_accuracy)\n",
        "\n",
        "    # Validación\n",
        "    model.eval()\n",
        "    validation_loss = 0\n",
        "    correct = 0; total = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            outputs = model(X_batch)  # Obtenemos logits\n",
        "\n",
        "            # Calcular la pérdida para cada elemento en el batch (sin reducción)\n",
        "            loss = loss_function(outputs, y_batch.argmax(dim=-1))\n",
        "\n",
        "            validation_loss += loss.item() * X_batch.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += y_batch.size(0)\n",
        "            correct += (predicted == y_batch.argmax(dim=1)).sum().item()\n",
        "\n",
        "    validation_loss /= len(test_loader.dataset)\n",
        "    validation_accuracy = 100 * correct / total\n",
        "    history['val']['loss'].append(validation_loss)\n",
        "    history['val']['acc'].append(validation_accuracy)\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
        "    print(f'Epoch {epoch+1}, Val Loss: {validation_loss:.4f}, Val Accuracy: {validation_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Xpwr5dSpsS0r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from math import log\n",
        "\n",
        "def normalize_input(X):\n",
        "    # features = [V, Loss, CS, 1/n]\n",
        "\n",
        "    # Pasar a escala logarítmica\n",
        "    '''\n",
        "    for input in X:\n",
        "        for fvector in input:\n",
        "            # Convertir Loss a (1 - Loss)\n",
        "            fvector[1] = 1 - fvector[1]\n",
        "\n",
        "            for i in range(len(fvector)):\n",
        "                fvector[i] = log(fvector[i], 10) if fvector[i] > 0 else 999999\n",
        "    '''\n",
        "\n",
        "    # Escalar con StandardScaler\n",
        "    # X shape: [num_ejemplos, num_acciones, 4]\n",
        "    X = np.array(X, dtype=np.float32)\n",
        "\n",
        "    # Aplano a 2D\n",
        "    X_flat = X.reshape(-1, X.shape[-1])  # [num_ejemplos*num_acciones, 4]\n",
        "\n",
        "    # Fit/transform\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_flat)\n",
        "\n",
        "    # Vuelvo a la forma original\n",
        "    X = X_scaled.reshape(-1, X.shape[1], X.shape[2])\n",
        "    return X\n",
        "\n",
        "\n",
        "def curriculum_learning(model, datasets, epochs, weights, train_size, test_size, batch_size, learning_rate):\n",
        "    # Cargar los datasets\n",
        "    data = []\n",
        "    for dataset in datasets:\n",
        "        X, Y, blocks_ids = load_data_from_file(dataset)\n",
        "        X, Y, _ = remove_elements_with_zero(X, Y, blocks_ids)\n",
        "        X = normalize_input(X)\n",
        "        X = torch.tensor(X)\n",
        "        Y = torch.tensor(Y)\n",
        "        data.append((X, Y))\n",
        "\n",
        "    # Inicializar el modelo, la función de pérdida y el optimizador\n",
        "    loss_function = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Histórico de métricas\n",
        "    history = {split: {'loss': [], 'acc': []} for split in ['train', 'val']}\n",
        "\n",
        "    # Ciclo de entrenamiento por fases\n",
        "    for phase_idx in range(len(datasets)):\n",
        "        # Determinar la distribución de los datasets por fase\n",
        "        total_weight = sum(weights[:phase_idx + 1])\n",
        "        weights_normalized = [w / total_weight for w in weights[:phase_idx + 1]]\n",
        "\n",
        "        # Crear DataLoaders para los datasets de la fase\n",
        "        train_loader_list = []\n",
        "        test_loader_list = []\n",
        "\n",
        "        # Para cada dataset en la fase, usar su peso para determinar la cantidad de muestras\n",
        "        for idx, (X, Y) in enumerate(data[:phase_idx + 1]):\n",
        "            weight = weights_normalized[idx]\n",
        "\n",
        "            # Número de muestras para el conjunto de entrenamiento y validación (según peso)\n",
        "            num_train_samples = int(weight * train_size)\n",
        "            num_test_samples = int(weight * test_size)\n",
        "\n",
        "            # Crear un dataset general\n",
        "            dataset = TensorDataset(X, Y)\n",
        "\n",
        "            # Separar los datos para entrenamiento y prueba sin solapamiento\n",
        "            # Primero obtenemos el conjunto de entrenamiento\n",
        "            train_dataset, remaining_dataset = random_split(dataset, [num_train_samples, len(dataset) - num_train_samples])\n",
        "\n",
        "            # Luego, del resto de datos, obtenemos el conjunto de prueba\n",
        "            test_dataset, _ = random_split(remaining_dataset, [num_test_samples, len(remaining_dataset) - num_test_samples])\n",
        "\n",
        "            # Crear los DataLoader para cada dataset\n",
        "            train_loader_list.append(DataLoader(train_dataset, batch_size=batch_size, shuffle=True))\n",
        "            test_loader_list.append(DataLoader(test_dataset, batch_size=batch_size, shuffle=False))\n",
        "\n",
        "        # Ciclo de entrenamiento para cada fase\n",
        "        for epoch in range(epochs[phase_idx]):\n",
        "            model.train()\n",
        "            train_loss = 0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            # Combinar los datos de los datasets para el conjunto de entrenamiento\n",
        "            current_train_loader = []\n",
        "            for loader in train_loader_list:\n",
        "                current_train_loader.extend(loader)\n",
        "\n",
        "            # Entrenamiento\n",
        "            for X_batch, y_batch in current_train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(X_batch)\n",
        "                loss = loss_function(outputs, y_batch.argmax(dim=-1))\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item() * X_batch.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += y_batch.size(0)\n",
        "                correct += (predicted == y_batch.argmax(dim=1)).sum().item()\n",
        "\n",
        "            train_loss /= total  # Promedio de la pérdida\n",
        "            train_accuracy = 100 * correct / total\n",
        "            history['train']['loss'].append(train_loss)\n",
        "            history['train']['acc'].append(train_accuracy)\n",
        "\n",
        "            # Validación\n",
        "            model.eval()\n",
        "            validation_loss = 0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                current_test_loader = []\n",
        "                for loader in test_loader_list:\n",
        "                    current_test_loader.extend(loader)\n",
        "\n",
        "                for X_batch, y_batch in current_test_loader:\n",
        "                    outputs = model(X_batch)\n",
        "                    loss = loss_function(outputs, y_batch.argmax(dim=-1))\n",
        "                    validation_loss += loss.item() * X_batch.size(0)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += y_batch.size(0)\n",
        "                    correct += (predicted == y_batch.argmax(dim=1)).sum().item()\n",
        "\n",
        "            validation_loss /= total\n",
        "            validation_accuracy = 100 * correct / total\n",
        "            history['val']['loss'].append(validation_loss)\n",
        "            history['val']['acc'].append(validation_accuracy)\n",
        "\n",
        "            print(f'Epoch {epoch + 1}/{epochs[phase_idx]}, Phase {phase_idx + 1} - Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
        "            print(f'Epoch {epoch + 1}/{epochs[phase_idx]}, Phase {phase_idx + 1} - Val Loss: {validation_loss:.4f}, Val Accuracy: {validation_accuracy:.2f}%')\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "j7jc2TriuO46"
      },
      "outputs": [],
      "source": [
        "# Parámetros del modelo\n",
        "input_dim = 4  # Dimensión de la entrada\n",
        "num_heads = 8  # Número de cabezas en la atención multi-cabeza\n",
        "head_dim = 16  # Dimensión de cada cabeza\n",
        "num_layers = 6  # Número de capas\n",
        "\n",
        "# Crear el modelo\n",
        "model = CLPModel(input_dim=input_dim, num_heads=num_heads, head_dim=head_dim, num_layers=num_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQOLXGxntcx9",
        "outputId": "a5bc1fdc-3937-4639-d984-14c98c342059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Phase 2 - Train Loss: 1.4759, Train Accuracy: 73.33%\n",
            "Epoch 1/20, Phase 2 - Val Loss: 1.2945, Val Accuracy: 66.33%\n",
            "Epoch 2/20, Phase 2 - Train Loss: 1.2145, Train Accuracy: 73.42%\n",
            "Epoch 2/20, Phase 2 - Val Loss: 1.1686, Val Accuracy: 67.67%\n",
            "Epoch 3/20, Phase 2 - Train Loss: 1.2162, Train Accuracy: 73.50%\n",
            "Epoch 3/20, Phase 2 - Val Loss: 1.0980, Val Accuracy: 68.67%\n",
            "Epoch 4/20, Phase 2 - Train Loss: 1.1830, Train Accuracy: 74.42%\n",
            "Epoch 4/20, Phase 2 - Val Loss: 1.1203, Val Accuracy: 69.00%\n",
            "Epoch 5/20, Phase 2 - Train Loss: 1.2407, Train Accuracy: 74.83%\n",
            "Epoch 5/20, Phase 2 - Val Loss: 1.1383, Val Accuracy: 68.33%\n",
            "Epoch 6/20, Phase 2 - Train Loss: 1.2236, Train Accuracy: 73.67%\n",
            "Epoch 6/20, Phase 2 - Val Loss: 1.1862, Val Accuracy: 67.33%\n",
            "Epoch 7/20, Phase 2 - Train Loss: 1.1902, Train Accuracy: 74.42%\n",
            "Epoch 7/20, Phase 2 - Val Loss: 1.1103, Val Accuracy: 68.00%\n",
            "Epoch 8/20, Phase 2 - Train Loss: 1.1299, Train Accuracy: 75.50%\n",
            "Epoch 8/20, Phase 2 - Val Loss: 1.1242, Val Accuracy: 68.00%\n",
            "Epoch 9/20, Phase 2 - Train Loss: 1.1202, Train Accuracy: 75.58%\n",
            "Epoch 9/20, Phase 2 - Val Loss: 1.1261, Val Accuracy: 67.00%\n",
            "Epoch 10/20, Phase 2 - Train Loss: 1.1148, Train Accuracy: 76.00%\n",
            "Epoch 10/20, Phase 2 - Val Loss: 1.1146, Val Accuracy: 67.67%\n",
            "Epoch 11/20, Phase 2 - Train Loss: 1.1107, Train Accuracy: 75.75%\n",
            "Epoch 11/20, Phase 2 - Val Loss: 1.1166, Val Accuracy: 68.33%\n",
            "Epoch 12/20, Phase 2 - Train Loss: 1.0757, Train Accuracy: 76.00%\n",
            "Epoch 12/20, Phase 2 - Val Loss: 1.1961, Val Accuracy: 65.00%\n",
            "Epoch 13/20, Phase 2 - Train Loss: 1.0926, Train Accuracy: 75.92%\n",
            "Epoch 13/20, Phase 2 - Val Loss: 1.2114, Val Accuracy: 65.67%\n",
            "Epoch 14/20, Phase 2 - Train Loss: 1.0839, Train Accuracy: 75.25%\n",
            "Epoch 14/20, Phase 2 - Val Loss: 1.0803, Val Accuracy: 70.00%\n",
            "Epoch 15/20, Phase 2 - Train Loss: 1.0694, Train Accuracy: 77.17%\n",
            "Epoch 15/20, Phase 2 - Val Loss: 1.1234, Val Accuracy: 68.33%\n",
            "Epoch 16/20, Phase 2 - Train Loss: 1.1045, Train Accuracy: 76.33%\n",
            "Epoch 16/20, Phase 2 - Val Loss: 1.1536, Val Accuracy: 67.00%\n",
            "Epoch 17/20, Phase 2 - Train Loss: 1.0278, Train Accuracy: 76.92%\n",
            "Epoch 17/20, Phase 2 - Val Loss: 1.1353, Val Accuracy: 66.67%\n",
            "Epoch 18/20, Phase 2 - Train Loss: 1.0630, Train Accuracy: 77.25%\n",
            "Epoch 18/20, Phase 2 - Val Loss: 1.3208, Val Accuracy: 63.67%\n",
            "Epoch 19/20, Phase 2 - Train Loss: 1.0106, Train Accuracy: 76.75%\n",
            "Epoch 19/20, Phase 2 - Val Loss: 1.2128, Val Accuracy: 63.33%\n",
            "Epoch 20/20, Phase 2 - Train Loss: 0.9964, Train Accuracy: 77.42%\n",
            "Epoch 20/20, Phase 2 - Val Loss: 1.2802, Val Accuracy: 64.67%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [1.4759207248687745,\n",
              "   1.2144553073247273,\n",
              "   1.2162444837888082,\n",
              "   1.1830488626162212,\n",
              "   1.2407187481721242,\n",
              "   1.2235941394170124,\n",
              "   1.1902378837267558,\n",
              "   1.1299270296096802,\n",
              "   1.1201626014709474,\n",
              "   1.114825999736786,\n",
              "   1.110683526992798,\n",
              "   1.0757223645846048,\n",
              "   1.0925645661354064,\n",
              "   1.0838728332519532,\n",
              "   1.0694393765926362,\n",
              "   1.1044625250498454,\n",
              "   1.0277729475498198,\n",
              "   1.063039231300354,\n",
              "   1.010594958861669,\n",
              "   0.9964226281642914],\n",
              "  'acc': [73.33333333333333,\n",
              "   73.41666666666667,\n",
              "   73.5,\n",
              "   74.41666666666667,\n",
              "   74.83333333333333,\n",
              "   73.66666666666667,\n",
              "   74.41666666666667,\n",
              "   75.5,\n",
              "   75.58333333333333,\n",
              "   76.0,\n",
              "   75.75,\n",
              "   76.0,\n",
              "   75.91666666666667,\n",
              "   75.25,\n",
              "   77.16666666666667,\n",
              "   76.33333333333333,\n",
              "   76.91666666666667,\n",
              "   77.25,\n",
              "   76.75,\n",
              "   77.41666666666667]},\n",
              " 'val': {'loss': [1.2944805749257406,\n",
              "   1.1686315822601319,\n",
              "   1.097958917617798,\n",
              "   1.1203376865386963,\n",
              "   1.138338181177775,\n",
              "   1.1862380282084146,\n",
              "   1.1102726904551188,\n",
              "   1.1241958300272623,\n",
              "   1.1261176331837972,\n",
              "   1.114614617029826,\n",
              "   1.1165722370147706,\n",
              "   1.1960604413350424,\n",
              "   1.211432129542033,\n",
              "   1.0803258991241456,\n",
              "   1.1233697350819905,\n",
              "   1.1536449337005614,\n",
              "   1.1352694861094157,\n",
              "   1.320770591100057,\n",
              "   1.2127533721923829,\n",
              "   1.280219144821167],\n",
              "  'acc': [66.33333333333333,\n",
              "   67.66666666666667,\n",
              "   68.66666666666667,\n",
              "   69.0,\n",
              "   68.33333333333333,\n",
              "   67.33333333333333,\n",
              "   68.0,\n",
              "   68.0,\n",
              "   67.0,\n",
              "   67.66666666666667,\n",
              "   68.33333333333333,\n",
              "   65.0,\n",
              "   65.66666666666667,\n",
              "   70.0,\n",
              "   68.33333333333333,\n",
              "   67.0,\n",
              "   66.66666666666667,\n",
              "   63.666666666666664,\n",
              "   63.333333333333336,\n",
              "   64.66666666666667]}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "datasets = [\"E4-datasets/1-1.data\", \"E4-datasets/2-7.data\", \"E4-datasets/8-64.data\"]\n",
        "epochs = [0, 20, 0]\n",
        "weights = [4, 1, 1]\n",
        "train_size = 1200\n",
        "test_size = 300\n",
        "batch_size = 32\n",
        "learning_rate = 1e-4\n",
        "\n",
        "curriculum_learning(model, datasets, epochs, weights, train_size, test_size, batch_size, learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XjzvruUaC65"
      },
      "source": [
        "# Ejecutable (testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrcF73EYMUHA"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/rilianx/Metasolver.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwWxcDFfMlDA"
      },
      "outputs": [],
      "source": [
        "!cmake .\n",
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECFvgjggShuj"
      },
      "outputs": [],
      "source": [
        "!./BSG_CLP --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJaZdyDlWJW2"
      },
      "outputs": [],
      "source": [
        "!./BSG_CLP prueba.txt -i 1 -w 8 --verbose2=64"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKLUNOLt765P9F43G0mLrW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}